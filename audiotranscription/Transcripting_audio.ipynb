{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pvilA0cEZEW",
        "outputId": "8101a1f0-7942-42bc-ff8f-d853a862cad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper --quiet\n",
        "# ou, se preferir pegar direto do GitHub:\n",
        "# !pip install -U git+https://github.com/openai/whisper.git --quiet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2r-ZBwbHftG",
        "outputId": "dea5fd41-1a36-4d63-ef8c-366541b13fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'2025-05-22 12-59-16.wav'\n",
            "'2025-05-29 13-58-52.wav'\n",
            "'2025-06-27 15-31-43.wav'\n",
            "'2025-07-01 10-20-25.wav'\n",
            "'2025-07-02 10-28-59.wav'\n",
            "'2025-07-02 14-54-54.wav'\n",
            "'2025-07-10 07-42-44.wav'\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Pega todos os arquivos .wav da pasta atual (ou mude o caminho)\n",
        "audio_files = list(Path(\"/content\").glob(\"*.wav\"))\n",
        "\n",
        "# Mostra os nomes\n",
        "for file in audio_files:\n",
        "    print(file.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsQxJGmrM-7x",
        "outputId": "44d8c35d-9a05-482a-ff82-279720bd4579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 13-27-16.wav\n",
            "2025-06-23 15-58-08.wav\n",
            "2025-06-27 15-31-43.wav\n",
            "2025-05-23 09-37-03.wav\n",
            "2025-05-22 13-28-12.wav\n",
            "2025-07-02 14-54-54.wav\n",
            "2025-07-01 10-20-25.wav\n",
            "2025-07-02 10-28-59.wav\n",
            "2025-07-10 07-42-44.wav\n",
            "2025-06-12 14-57-34.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pathfile in audio_files:\n",
        "  print(pathfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-u0JH3jNXzf",
        "outputId": "38cbbbfb-4139-4d89-8eac-5cc645a4ce39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/2025-06-18 13-27-16.wav\n",
            "/content/2025-06-23 15-58-08.wav\n",
            "/content/2025-06-27 15-31-43.wav\n",
            "/content/2025-05-23 09-37-03.wav\n",
            "/content/2025-05-22 13-28-12.wav\n",
            "/content/2025-07-02 14-54-54.wav\n",
            "/content/2025-07-01 10-20-25.wav\n",
            "/content/2025-07-02 10-28-59.wav\n",
            "/content/2025-07-10 07-42-44.wav\n",
            "/content/2025-06-12 14-57-34.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "Z1BgqeSzFBNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")\n",
        "result = model.transcribe(\"2025-06-27 15-31-43.wav\")\n",
        "print(\"🌍 Idioma detectado:\", result[\"language\"])\n",
        "print(\"📝 Transcrição:\", result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvh5eRbLFEQu",
        "outputId": "aab9421c-81d6-43b3-d968-1c6509c24c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 Idioma detectado: en\n",
            "📝 Transcrição:  the company, the role, the team, I'll get to know a little bit more about you. You'll also get to know a little bit more about me. And then we'll also have some, it's time for questions at the end. Perfect. Sound good? All right. So, the screening interview questions kind of gave you a little bit of a taste of what we provide, or at least in the context of the role. So I'll just start over, try not to be too repetitive, but it may be a little bit, just because like I said, it's kind of hard to do those questions without enough context. So, Sensor Tower is the market leader for mobile analytics. So our bread and butter has to do with, providing estimates of like downloads, revenue, active users. These are things that help customers understand like who's using an app, who's spending money in it, so that they can actually derive insights for what they should be doing next for their own business. And so, in terms of the role as an analyst, like I said last time, our bread and butter is in supporting the legacy data AI metrics on my team. So, data AI used to be the other market leader of mobile analytics. We were direct competitors of one another, and we merged together last year through an acquisition, and my team came through that acquisition. And so, obviously the long-term plan is to have one platform that everyone goes to that is the best of both worlds. We actually had an initiative just released, which was called Better Together, which was aiming to do that, having the estimates that are the best of both technologies. But as you can imagine, there's some friction. Obviously customers were not involved in the acquisition, and probably were very happy that there were two sources of this kind of data. And so, until we're able to migrate everyone off, we're gonna have to support the legacy data metrics, which is what a good, it's the highest priority of my team, because there's a lot of money behind it, and we still have a good number of clients who haven't migrated over yet to Sensor Tower. And so, the kind of bread and butter of the role is to, for one of the pipelines, kind of look at the estimates before they go to customers every week, and intervene if there's any issues. And then, like I said, there's also customer questions that can come in. The other point of the role, though, is much more than that, right? It really depends on how noisy things are for the legacy pipelines. If everything's smooth sailing, and there's not too much to have to deal with, usually people on my team will spend about two days working on the QA of these data sets. My hope is that then the rest of the time, they're able to do other things. So Sensor Tower is cool in that we're pretty flat in terms of our organization, and we're pretty agnostic when it comes to the title. So they would rather see people show their spirit in however it manifests. So there are some engineers who build products without any sort of data science involvement in their data scientists who build engineering pipelines. It really doesn't matter what your title is. And so the people who have been most successful on my team are the ones who have their kind of main focus, but then also really love diving into interesting questions and trying new things and building new things that provide value to the company. And so that's hopefully what the rest of the time will be spent on. Obviously, there will be some weeks where something goes wrong, there's issues in that it might be the whole week that you're working on. Legacy data stuff really just depends. The team itself, I started out only having machine learning engineers and data scientists. Acquired the analyst team last year. Oh, excuse me. I had people from the analyst team join my team last year. And right now we're kind of settling around having analysts on the team. But like I said, they are analysts mostly in title. We have some people doing more data science projects. We have some people doing more machine learning, engineering, engineering projects. That's the makeup of the team. And I'll pause here in case you have questions. No, that's perfect. You already answered a lot of my questions, the questions that I had here. Okay. But I have a lot, so I don't know if it's the time to ask all the questions or... Does it relate to the stuff I've been talking about? Yeah, also about... You already said a little bit about the team and you're the leader that was one of my questions. And... Okay, so it's like the team collaborative. Like everyone has their own tasks, but they help each other sometimes. How is the feeling in the group? Yeah, so I encourage people to work together. I don't like when people are siloed. Sometimes it's a necessity of the project, but we have team meetings for project updates once a week, and then we have team meetings for project discussions. And my hope is through that and individual meetings that people will set up one another. The goal is that that's giving them kind of the exposure to others on the team. But then also we work very closely with engineering, other data science teams, things like that. Yeah, that's really nice. You said also that the work that we do, it's not tied to the role name, let's say like this. So this is a thing that I'm really interested because I'm looking forward to a place that can challenge me and give me space to try new things, right? So I love to analyze data, but I would like also to have the opportunity to model data if it's possible to apply, I don't know, some JNAI technologies and everything. So that's really nice, yeah. OK. Yeah, that's one of the questions I was going to ask. Did you have other questions? Yeah. You already answered about the stakeholders. So we're going to deal with clients, but also other kinds of stakeholders? So clients come through support tickets. So the support teams, the first one, they're the ones directly talking to clients. It's just tickets will be assigned to you if support can't figure out what they should help with. Other stakeholders, like I said, will be engineering, product, sales. It really just depends. Could be all they have. Nice. And OK, about the data. Can I ask about the data? Is the data already structured? Because on the world description, it talks a lot about the data quality. So I think that maybe there is a non-structure, but we have to take a look at the quality to clean and everything. Is there a lot to do in the data? Or the data is mostly perfect? I don't know if there's a role that the data is perfect, but yeah. We do have a distinct data engineering team, such that by the time you touch it, it's structured. Nice. Not saying that it's perfect. There is always. There is always something to do. Yeah, no, I think for now. Yeah, for now. I'm OK. OK. So yeah, you answer the question about what you're looking for. So if I remember correctly, let's see. Yeah, I think you have already had more industry experience, but I don't think that's going to be a problem. Sometimes people come in with more product data analysts or data scientist roles where a lot of what they do is like A-B testing. So I don't think there's as much of a problem here, because I think that you've already had experience like analyzing data sets in a similar way that we do. It's just that I would love it if you could take it step further and actually build pipelines and things like that. And so I think you've had enough experience where that shouldn't be a problem. So I will skip that. So what in the experiences that you've had, it looks like there's a lot of more research projects. I'd love to hear more about what you specifically have done, like how you've kind of either pioneered things or kind of brought a project from beginning to end. Like I want to understand like how you demonstrate that you're a self-starter and can bring a successful project to a close. OK, yeah. So the last company that I worked, it was I don't know if I already told you about that, but it was a company that inspects wind turbines. And with inspections, they collect the data about the damage on the blades of the wind turbines. So my role was to analyze all this data and bring new insights. So I had to, I created a dashboard about market share for them to understand which part of the market they were inspecting and where they could expand the inspections. And I worked with lightning. So I had to work with lightning data. It's weather data to understand when the lightning was causing more damage on the blades. So I had to use both data. And identify the power. It's when a wind turbine has, they want to replace all the turbines. So two new ones. And there was any flag on the data saying where, when the turbine was, all the turbines were replaced. So I had to figure it out with all the data that we have. And also the images. Sometimes I had just to look both images and see if they replaced the turbine or not. And I worked as well with failure. And we didn't predict a failure, but I started it's analysis of understanding when could failure. But my most powerful project that I worked with was with repair cost prediction. So I worked with the blade engineers and TEI team, where the specialists, they had a rule that should be applied to all the damage to predict the repair cost of each damage. So I had to clean the data and apply the rules, make all the logic for the rules. Because they did in a kind explaining way. If this happened, so this should happen. So I had to translate the rules for a logic program. Then after this, I applied to all the data and automated this. This prediction to the repair cost. So we had to run every week because every week we had new data. And so we use Python and Databricks to create. I use Python and Databricks to create a job to automate this. It wasn't a pipeline person, but I had to automate the cleaning and everything to get to the new data at the end. So these were the ones that I was leading the project. So I had to always be in contact with the blade engineer and the other team to be if they were satisfied. And when the logic was done, they were really happy with the results. Because this data, they could create a new project to the client that they to say to them that when will be the perfect time to repair damage. So we had the actual damage and also the projection to see if they will get worse. So you can repair the damage now and it will cost like 1000 euro. But if you wait till the next year, it'll cost 5000 euro. So maybe it's better for you to repair now. Or if you don't repair now next year, even if it gets worse, you won't increase that much the repair cost. So this was one of the big projects that I was in. But most of the time I was cleaning data and building a lot of dashboards. I also created dashboards to see because there was a lot of data sets that I have to clean and put on our data bricks to the other data scientists analyze and continue to their works. So I created as well a dashboard to monitoring the data if the data were updating correctly, how long the last update was. And yeah, it was a lot of things. But the biggest one were the repair costs. That's cool. Would you be able to speak to, let's say this is even for a job, a project where you just wanted to understand something better. And so you built a project around understanding that question, maybe modeling something and then analyzing the results. Yeah, I mean, yeah, it depends. But yeah, I just have to understand the question and understand the data. I think the first step is always understand the data and then analyze it and put it in a simple way to explain what was done. But yeah, that's it. That's the thing that I did every day. Yeah. Oh, something outside of your normal, like you can walk with it. Can you reformulate the question? So there's your day-to-day tasks that you're expected to do. And maybe you have quarterly deliverables. These are the projects that you committed to doing. Were there any projects that were outside of those? Like maybe no one had bandwidth to work on and you were like, I want to look into it. Or I just have this idea. Can I go try it, manager? Yeah, actually, there were two projects that I asked to do because there was anyone who would like to do it and I was interested in it. One that I understand that the data had duplicate observations, but it's not in an easy way to understand the duplicates because when they, it was a messy sometimes because let's say there's a turbine with the ID and sometimes when they replace a turbine, the ID continues the same, but all the features of the turbine change. And sometimes they replace the turbine and the ID, it's a new ID. The ideal world would be, it's the same ID because it's the same location. And it's considered to be the same turbine even changing everything. So I asked them to analyze this and get to a solution to create a data set for them to understand when it's the same turbine, when they have to filter because sometimes if the turbines have two different IDs, they will have different images. So would you like to join everything? Would you like to use just an ID for one classroom or you'll have to filter? So yeah, I have to get the leads to this one. I asked to work with this one because it was a significant amount of turbines that had this issue. So yeah, one of the things were like this and one of the other things that I asked to work was to identify the repower turbines. So yeah, both and the repower turbines, I had to look for external sources because we didn't have the data in our database. So for turbines, we have a public turbine data set on the US. So I just had to join both turbines, both data, but it was challenging because it's different to identify the turbines, but improve our data and I could create this new data that identified the repower. So yeah, I had two opportunities, probably more, but this is the most that it's pertaining to my mind. Okay, can you actually talk a little bit more about the makeup of the team that you're on? Like do you have other data scientists you work with? Yeah, my team was only data scientists. Everybody was data scientists, but the company was focused on machine learning. We did more analysis, different analysis that we had on the types to apply machine learning. I was always asking to do this. Even the last one, the repair cost prediction. At the end, I was trying by my own to apply some machine learning to predict the cost instead of using the rules. But I even did the pipeline, but I didn't get to the deploy anything. But it was a good experience. Can you explain, so you were primarily working with data scientists, but I would imagine that you would have to talk and give presentations to non-data scientists, is that right? Yeah, in this role I was dealing, yeah. I dealt with blade engineers and the manager, the financial manager, he was always asking for some insights, some plots to presentation to clients and everything. We had daily, not daily, weekly meetings with different kinds of different teams in the company. Sometimes it was with marketing people, sometimes with financials, sometimes with the blade engineers. Let me see. Yeah, sometimes I don't even remember the other teams, but we had a lot of meetings with a lot of different teams. If you're a data scientist, you have to learn how to speak non-statistical and analytical things to explain. But yeah, I had a lot of opportunities to do this. Can you explain what a typical, how often would you talk to non-technical audiences? It wasn't that often. I was mostly talking to my teammates and the data engineers. The blade engineers were most twice in a month, or the financial manager was right at the beginning when I entered. Have you ever had a tricky conversation happen and how did you resolve it? Yeah, there's always tricky conversations because sometimes they ask things and it's not clear what they want, actually. Sometimes it's a contrary. We, I, presented insights and they didn't understand. I think the right way is always have a clear communication, ask more questions about what are they asking, what are they focusing to try to understand the task, or at the other side explain in a, not, it could be in a difficult way, but in a logic way that they could understand in their role. So yeah, I think it was always like that. One time when I was in my internship, I did an internship at a study station. And I was really excited with everything that I was learning in the university. And I was trying to apply everything in the data that HR gave to me. They didn't ask me anything, they just asked me to analyze. And so I was free to do everything that I want. So I was applying a lot of techniques and when I bring the report to them, they were happy, but then every day during like three months, they were asking me, what does this mean? Because I don't understand. So I had to explain everything, even a box plot, they didn't understand. And then I got it that some, like, even some plots are not for everyone to get a look. But yeah, I had to explain everything. It was really good, it was a really good experience because it was a team that didn't work with data and it wasn't understanding why I did everything that I did. But yeah, it was challenging, but it was a good experience. Can you speak to what a typical timeline is for the projects that you work on? The timeline, yeah, usually, if you already know the data, but if you don't know the data, the first time it's understand the data, get some profiling, but exploration rights, understand all the variables, the range of the variables, if everything is clean, and then begin to analyze. So it depends on the context, what do they want for the data, if they want just some KPIs or if they want a dashboard, or if they want modeling. And it starts with building everything. At the end, also it'll depend on what they're asking for this data, but it could be a report, it could be a dashboard, it could be a modeling, it could be just some plotting. But in the middle, I always try to get some feedback if the result is going well or it's making sense. But yeah, this is usually the timeline, it's just your question, the timeline. Yeah, like a typical project from beginning to end takes a lot. Yeah, so it'll depend on the project, but mostly it's like beginning with understanding the data, if you have to be clean, clean the data, and start the analysis, get some feedback in the middle to see if it's going well, and in the end what it has to be developed. Yeah, what's the time? Okay, sorry. Yeah, this will depend on the project. Yeah, but we usually work with two weeks in spring, but it depends also if it's only analyzing, creating plots. So usually two or three days if the data doesn't need to be clean, modeling for a first approach, I think one week. So, but it'll depend also on the deadline, because the deadline could give you more room to explore more things, but if it's a short deadline, you have to be direct with the analysis or anything you have to do. But at dashboard, it'll depend also on the tool that you are using. So, a dashboard could be quick or it could take months if you're building a dashboard, like with R. We probably use Tableau, are you familiar with it? So, I took a look on Tableau, it looks like Power BI, right? I have some knowledge in Power BI, and I worked with, I don't know if you know, Databricks have some dashboards inside, so I worked with Databricks dashboards and R dashboards. I don't know if you'll know also, you'll have to build a dashboard from scratch coding. Yeah, but I love Power BI, so probably it'll be easy to use Subblue as well. Okay, I think those are my questions, do you have any more? Nice. Yeah, okay, about the career path, do you know if the company has some sort of structure career path? We don't have specific company-wide ones. We're working on more formalizing within specialization ones because for the data science teams, it's pretty straightforward, right? You're a junior, then you're a data scientist, then you're a senior. It's pretty straightforward, same thing with analysts. So, we don't really need to because it's pretty obvious, but putting goals to each stage. Yeah, this would be nice. What are the typical working hours? It really just depends. I definitely stress the team, you shouldn't feel like you need to work crazy hours. There are times when there's an incident, so if we have a really bad issue with our downloads estimates, the hours could go longer, but if that does happen, I tell them, hey, how much extra work did you put into this? And they're saying, I worked all weekend on this, I'm like, okay, we'll take a couple days off, you need to take a break. So, I feel like most people work pretty normal, like eight hour days. You're in Brazil, right? So, you should be in a similar enough time zone that you can work. You may need to shift a little bit for example, we're a global company, so we'll have people in Europe or people in Asia, so you might have to get up earlier, stay a little later, but most of the time it's normal hours. Okay, thank you. Yeah, about how the tests are assigned, like in monitor, is there a spring-based system or something like that? I wish we were more rigorous and have like sprints, but it's more like you have quarterly objectives and then I work with you to figure out, you know, which person would make sense to work on X projects and then like how that timeline looks is dependent on who's assigned and whatever we work together. It's just dependent on the needs. Nice. And usually, what are the deliverables? So, it's a dashboard, a report, what is it? A lot of the time it's just estimates, either an improvement on an estimate or building new estimates, that's mostly what happens. And what kind of language do you usually use? Is it Python? Is it R? We're Python on my team. The company does have a lot of infrastructure that's Ruby-based. You probably won't have to use it too much, but for example, engineers might give you a solution to a problem you're having in Ruby just because like that's what they know. But I think people are warming up to Python and it's kind of more necessary for the data professionals. Yeah, yeah, that's true. Yeah. I think R is dead now, right? I used R before this job and there's a special place for it, especially if you're doing statistics, but Python's nice because you can build packages like an app. So, and I think there are some functionalities that people are trying to build in Python, but I always have a special place for R in my life. Yeah, yes, well. And um I got one that I got lost in the question. We were talking about Python and R. Um, yeah. Um, go over to the desk. So, sorry, I'm just reading through all the more my questions. Okay. Yeah, I think just my final question is because you answered everything. I thought I did. It was 17 questions, but you were already answered everything. So, the last question is what are the next steps in the hiring process, if you can tell me? Yeah, so it's like fairly short of a process. So you have a screening interview, you have this interview, and then after this interview will be a take home where you have some time to work on a problem that's similar to something we might do at the company. Then you'll have an interview to go over the problem and like the results. And then we kind of like loosely have like an off-site or like an on-site structure where it's like the take home plus like some technical screen. So, a SQL slash like Python, PySpark screen will round it out. So, after that, it's pretty much, like after those two interviews, you're basically almost to the end. There might be another one with my manager if he wants to like meet with you and that'll probably be it. I think at that point, it's basically an offer. Okay, well, I hope you have a good rest of your day. Thank you for taking the time out to speak with me and thank you. It was a pleasure for you too. All right, thank you. Bye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "audio_dir   = Path(\"/content\")          # ou \"/content/audios\"\n",
        "audio_files = list(audio_dir.glob(\"*.wav\"))\n",
        "\n",
        "model = whisper.load_model(\"small\")     # já carregado\n",
        "\n",
        "for audio_path in audio_files:\n",
        "    # 1) transcreve\n",
        "    result   = model.transcribe(str(audio_path))\n",
        "\n",
        "    # 2) troca \".wav\" por \".txt\" mantendo a mesma pasta e nome-base\n",
        "    txt_path = audio_path.with_suffix(\".txt\")\n",
        "\n",
        "    # 3) salva\n",
        "    txt_path.write_text(result[\"text\"], encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"✅ {txt_path.name} salvo!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "559GjI9RNFxj",
        "outputId": "60629f9a-82a2-4e9e-b240-3f79f62ec59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 2025-06-05 12-55-43.txt salvo!\n",
            "✅ 2025-06-18 13-27-16.txt salvo!\n",
            "✅ 2025-06-23 15-58-08.txt salvo!\n",
            "✅ 2025-06-27 15-31-43.txt salvo!\n",
            "✅ 2025-05-23 09-37-03.txt salvo!\n",
            "✅ 2025-06-05 11-26-43.txt salvo!\n",
            "✅ 2025-05-29 15-59-21.txt salvo!\n",
            "✅ 2025-05-22 13-28-12.txt salvo!\n",
            "✅ 2025-05-29 13-58-52.txt salvo!\n",
            "✅ 2025-07-02 14-54-54.txt salvo!\n",
            "✅ 2025-06-10 13-58-55.txt salvo!\n",
            "✅ 2025-07-01 10-20-25.txt salvo!\n",
            "✅ 2025-07-02 10-28-59.txt salvo!\n",
            "✅ 2025-06-02 09-54-09.txt salvo!\n",
            "✅ 2025-07-10 07-42-44.txt salvo!\n",
            "✅ 2025-06-12 14-57-34.txt salvo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iaPRteSJxnqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcripts = []\n",
        "for txt_file in Path(\"/content\").glob(\"*.txt\"):\n",
        "    text = txt_file.read_text(encoding=\"utf-8\")\n",
        "    transcripts.append({\"arquivo\": txt_file.name, \"texto\": text})\n",
        "\n",
        "df = pd.DataFrame(transcripts)"
      ],
      "metadata": {
        "id": "tGDJb2vxMo16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Dk221Jyxxqow",
        "outputId": "40689f0f-524e-445c-93b9-df97742c168f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    arquivo                                              texto\n",
              "0   2025-06-10 13-58-55.txt   I will make fun ice cream忙을 Blueberry ma yeah...\n",
              "1   2025-05-29 15-59-21.txt   Generally, as far as I do gotta separate othe...\n",
              "2   2025-06-02 09-54-09.txt   Youtube captions sponsoraring the school for ...\n",
              "3   2025-06-27 15-31-43.txt   the company, the role, the team, I'll get to ...\n",
              "4   2025-05-23 09-37-03.txt  ȓ TO maar � featuring o Bash의 � Bridges විවිවි...\n",
              "5   2025-07-02 10-28-59.txt   Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rha...\n",
              "6   2025-06-23 15-58-08.txt   e o meu amado já está com licença, olha já. V...\n",
              "7   2025-07-01 10-20-25.txt   you you you you you you Hello Erika, good mor...\n",
              "8   2025-06-05 11-26-43.txt   2018 2017 entend guitar Foreign中 Tell me Buon...\n",
              "9   2025-05-22 13-28-12.txt   customs m of  upgrad <|th|><|zh|> Soft Waves ...\n",
              "10  2025-07-02 14-54-54.txt   ស្្ ស្ម្្្ វ្្្ ល្្្ វ្្្្ ḏᵉ ḅᶥᶜᵗ Ḁᶠᶠᶜ Ὁᵎᶜᶜᶠ...\n",
              "11  2025-07-10 07-42-44.txt   ᴛ ᴠᵍᴏᵋ ḍᵍ ᶠᵃᵕᵃ ᶀ ᶜᶦᵦᶀᵉ ᶜᴃ�后ᶠ ᴛᵍᵏ ᶜʜᵃᴏᶡᶀ ᶧʜᵃᵃᴡ...\n",
              "12  2025-06-12 14-57-34.txt   you you you you you you you you you you you y...\n",
              "13  2025-05-29 13-58-52.txt   nd nîm nd nd nd nd nd nd nd nd nd nd nd nd nd...\n",
              "14  2025-06-18 13-27-16.txt   nifer o hetyn a hwnfciwy i fewn meddoriaeth o...\n",
              "15  2025-06-05 12-55-43.txt   7. × 9 × 22 – 3 × 10 Yes ä sister ä sister ot..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a478cd5-aae9-45e3-b0ca-55b33391fd30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arquivo</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-06-10 13-58-55.txt</td>\n",
              "      <td>I will make fun ice cream忙을 Blueberry ma yeah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-05-29 15-59-21.txt</td>\n",
              "      <td>Generally, as far as I do gotta separate othe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-06-02 09-54-09.txt</td>\n",
              "      <td>Youtube captions sponsoraring the school for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-06-27 15-31-43.txt</td>\n",
              "      <td>the company, the role, the team, I'll get to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-05-23 09-37-03.txt</td>\n",
              "      <td>ȓ TO maar � featuring o Bash의 � Bridges විවිවි...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-07-02 10-28-59.txt</td>\n",
              "      <td>Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-06-23 15-58-08.txt</td>\n",
              "      <td>e o meu amado já está com licença, olha já. V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-07-01 10-20-25.txt</td>\n",
              "      <td>you you you you you you Hello Erika, good mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-06-05 11-26-43.txt</td>\n",
              "      <td>2018 2017 entend guitar Foreign中 Tell me Buon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-05-22 13-28-12.txt</td>\n",
              "      <td>customs m of  upgrad &lt;|th|&gt;&lt;|zh|&gt; Soft Waves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-07-02 14-54-54.txt</td>\n",
              "      <td>ស្្ ស្ម្្្ វ្្្ ល្្្ វ្្្្ ḏᵉ ḅᶥᶜᵗ Ḁᶠᶠᶜ Ὁᵎᶜᶜᶠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-07-10 07-42-44.txt</td>\n",
              "      <td>ᴛ ᴠᵍᴏᵋ ḍᵍ ᶠᵃᵕᵃ ᶀ ᶜᶦᵦᶀᵉ ᶜᴃ�后ᶠ ᴛᵍᵏ ᶜʜᵃᴏᶡᶀ ᶧʜᵃᵃᴡ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-06-12 14-57-34.txt</td>\n",
              "      <td>you you you you you you you you you you you y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-05-29 13-58-52.txt</td>\n",
              "      <td>nd nîm nd nd nd nd nd nd nd nd nd nd nd nd nd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-06-18 13-27-16.txt</td>\n",
              "      <td>nifer o hetyn a hwnfciwy i fewn meddoriaeth o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-06-05 12-55-43.txt</td>\n",
              "      <td>7. × 9 × 22 – 3 × 10 Yes ä sister ä sister ot...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a478cd5-aae9-45e3-b0ca-55b33391fd30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a478cd5-aae9-45e3-b0ca-55b33391fd30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a478cd5-aae9-45e3-b0ca-55b33391fd30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-14314e81-a866-43bd-92e5-8137bedc3d60\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14314e81-a866-43bd-92e5-8137bedc3d60')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-14314e81-a866-43bd-92e5-8137bedc3d60 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_52f6f511-10eb-4689-8c41-e940551cae52\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52f6f511-10eb-4689-8c41-e940551cae52 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"arquivo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"2025-06-10 13-58-55.txt\",\n          \"2025-05-29 15-59-21.txt\",\n          \"2025-07-02 10-28-59.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" I will make fun ice cream\\u5fd9\\uc744 Blueberry ma yeah yeah yeah yeah oh hey yeah My boss was reading my message and he said that he didn't know me, but he was not a big fan of me. But thank you for being here and talking with us, you seemed to be a very calm person, very objective of us to meet, talk about company and also the position. I already met the historian and I did some process with us. I want to thank you for this opportunity and of course I knew the story. He already knows. And mainly because I follow the BBB a lot. And also because of this, in my city, it's full of machines. Oh, cool. So when I had the return, I was very excited. I was happy, because we managed to find a time to talk. And I wanted to understand how... I understood first, I'll talk a little about the position, then I'll talk a little more about us. But we are with this data scientist wave, base 2 here, within the structure of the credit risk team. And then thinking in a context, today we have this structure, there are three structures below the credit risk part. That is the part of the difference, not the difference, and the front of the PF. And then, with that, we are looking for a formal team, always with four people, so that each of these people is responsible for a specific project. So basically, this has been the challenge of the team at the moment. When we think about the burden, we are talking about a person who works with the credit part and obtains a lot of data sources, from cleaning and data organization, even thinking about the future engineering. Today we look a lot at data analysis using statistics techniques, learning about machines, so everything we talk about has tendancy, standards, in relation to determinism, what we are looking at. And the other topic is part of the development, implementation and the front of model validation. And that's what we talk about machine learning tools and other fronts there. When we think about the technical structure, today we are also working with Python and SQL, the part of the statistical analysis and machine learning, and the WS or the GCP, we are thinking of a cloud scenario. When we think about the data platform itself, we have the principle of the data bricks platform. So basically, this is the context of the position at the moment. Do you have any questions? No, for now, no. Good. I'll introduce myself a little bit, Erika, after I let you talk a little more about yourself, is there any problem in my computer? Everything is shaking, my screen. No, it's shaking. My computer is shaking, and it's the same, it's shaking too. Oh, ok, so it can be. But why am I here with the open video? Oh, I'm seeing that it's shaking, I thought, is it mine? You can't understand, but it's ok. I was going to say like that, but I have to go to the SES team to say that. I have to update myself, not buy a new one. No problem, don't worry. But I'm going to talk a little bit about me, Erika, your phone. You know me as PAN, PANZITA. Nobody calls me PAN, it's very rare to happen. I was here in Estonia for 5 years in September. I came here as a young foreigner, I came from a small chair, I didn't dream of running, it wasn't like that, what I really believed in career. My dream was to be a teacher, to study, because those kids couldn't have a good age, and it ended up in the middle of the road, I came to Estonia and talking to a girl, she said, PANZITA, my dream was to be the best aunt that a child ever had. I think it's a very cool idea, I think it's very cool who likes it, but then at the time she said, no, my dream is to be the one who makes the bet today, I feel the purpose, I feel only that I want, you know? So I understood that it makes sense to me to continue this college I was doing, it was a public college here in Rio, so it was very painful to leave a public college on the side. I cried every day, Erika said, I'm horrible, I don't know what to do, it's a very hard decision, because you have to decide so new, to make a change in career, and for me it was very painful, but I'm very suspicious of the decision I made, because I grew up very fast, I always had a lot of opportunities to let you work with amazing people here, since people with high seniority, people with the same seniority as me, so I see that it was something very productive, even for me personally, I grew up and matured very fast, so for me it was something... I can't say the words, I just wrote this, you know? But it's easier to make me want to go further in this career. No, it's serious, it's a big differential, the question is, be careful, what people have here, some with others, it's amazing. So then I can share my career with you, with more details, it was super sense to take a look, then calmly, so you understand what you have of growth opportunities, so I think it's a little bit like that, as I said, I'm too suspicious to say, so along the selective process, you will also meet other people, you will also be aligned with your career, and then I think it's a little bit like that, I would like to give you this space too, to get to know you a little better, who wants to be a professional person, who is in the technology field too, and if you can talk about your last experiences there, you are in the part of the data, so I'm in the question of the product you were working on, the part of the routine, to understand how it was working for you. Sure. So, I call him, I'm born and live here in Goi\\u00e2nia, my training is in statistics by the Federal University of Goi\\u00e1s, and at the moment I'm doing post-media in process of natural language and generative. It's still in the beginning, it's in the concepts, but it's something I'm enjoying a lot. I have about 5 years of experience in data analysis, and for several, let's say several fronts, I'm working as a statistical consultant, I'm working as a data analyst, as a data scientist, and my last great experience was in a company in Ireland, I lived there for 3 years, I worked there in the company called Skypex, it was called, automatically, biodeological turbines, so they used drones, they took pictures of the biodeological turbines, and there was a whole processing of the data that generated the data of the data they identified. So my role was to analyze these data, so besides collecting external data or creating data to complement the data of the data, I did a lot of cleaning because the data, my God, was the chaos, because besides being identified the data of the data, the data of the data of the customers who put several information, so I didn't come to standardize, I thought I should standardize everything, I had to do the maintenance of these data, I had to organize them, do several analysis, as I did market share analysis, identify the data with the most of the current of the waves, which is one of the transgisbilans against the wind turbines, which is a giant para-wave, and even if it has an anti-wave system, it's no use, the wind turbines burn the entire system, and that's it. It's complicated. I also worked identifying the failures that totally failed the turbine, because usually customers didn't tell us if the turbine was changed, or if it was changed, or if it failed, and all that. And one of my papers was to identify this, if the turbine was changed, if it was a great update of all the company, so I was able to identify this by changing the model, by not... if the damage had an old inspection, if all the damage had disappeared in the next inspection, so I had to do these analysis, sometimes it was very manual to look at an image and compare it to another image. I was also in front of a very cool project, which was the prediction of repair cuts, of these damage. So with these data, which I created with the help of engineers, and other areas, it was possible that it was a product that was created, in addition to the inspection, for the customer to have an signature, so it was to identify if the best way was to repair the data at that time, or if it could be more human, because if it repair now, it would be 1,000 euros, if in the next year it would be 10,000 euros. So sometimes now 1,000 euros, and in the next year it will still be 1,000 euros. So we made this prediction to help in this inspection. And I made a lot of graphs, a lot of best boards. I worked with Python daily, with the conversion of the code that I had with Git. And the Data Warehouse, which we gave was the Data Breaks, so I'm already familiar with Data Breaks, but I didn't have the opportunity to work with AWS, despite having done some courses that I had shown, how to use it, but professionally I didn't have the opportunity to apply any kind of tool. And good. But bad. Sorry, I was too much to say. It's okay, you can do it, I'm not saying everything you're saying here, and any question I'll give you. Sure, sure. So my goal in my career is always to be updated, always to have a good relationship with the team, with the bosses, I don't know if... I just have to say two words. Leader? Yeah, leader, that's right. With leader, we didn't have much contact with customers, but we needed to have contact with customers, too. And one of the very important things for me is to be able to explain the analysis that I do for the various areas, because when you talk to a data area, you can say something more complicated, but it's also important to pass these data to people who are not technical and who haven't even moved on their analysis. So I think it's a very important part. Well, I also want to try to solve the problems with activity, strategy, try to bring new technologies like this one I'm doing in the training, which is GMA, which is very high, using this kind of technology, like the ATT, to train and make them work for us. So... And then I'm passionate about data. The experience I had of machine learning, in case we didn't get to use machine learning automation. I was using this project I had for the review of the repair courses. First, I did an analysis, let's say, of several data that the turbine engineers passed because they had this knowledge of repair value. I worked, like this, weekly we would mark meetings to see if they were in agreement because they were waiting for the result of the data. And then in the end I proposed and started to apply this using machine learning. But even before that, before I left the company, they still didn't have the opportunity to learn because they said, no, we already have this knowledge. We don't want to depend so much on something that seems random. But the analysis was almost at the end. So I didn't get to put in production, but I had to update the data because they had already approved it. So in this issue, I already had the automation of scripts to update the cables in Databricks. Because they had to be updated. There were always new data, new damage and inspections that were always occurring in inspections in several different companies. So this creation of the data that I did had to be run every week. So I was responsible for, not only this, but other cables that had to be updated every week. So I created jobs in Databricks. How do we do it if it goes wrong or not. Now I'm here telling you, happy, grateful for the opportunity and looking for new challenges to apply the knowledge of the scientists, the engineers, the creation of dashboards, all because the story needs to be in the disposal so that we can see if this partnership will be a good partnership. Good. The area was super clear to me. And then we have some questions. You talked a lot about the career part. And then I want to understand a little how you are today. What are your expectations? So all of this. Yes, and this question would be a great opportunity if I could apply professionally these models that I'm learning, which would be LLM, then I would have to see how to apply them. And then I would have to see how to apply them. And then I would have to see how to apply them. So I would have to see how to apply the data of the story. But it's a data that works great. I just have to see what the opportunity is. But it would be something that I would really like to see and also be that person who the company says wow, this person is awesome in this matter. She already participated in several projects so if anyone needs it, you can go after Erika, who she will know. So this is a moment more or less professional that I am now. I just want the opportunity to get to know. Well, no, Benees Erika is super clear. And then I look at the issue of movimentations, right? What motivated you to look for new opportunities? What motivated you to look for the stone too? I was there in LLM, I was living there, including. And the company was very good. But it ended up having a change of leadership and they wanted a big lay off. So several leaders were sent away. And they ended up staying only with the seniors. So I ended up... But I was thinking about going back to Brazil. So it was just a... It was faster. We went back now at the end of the year, but then we ended up going back at the beginning of the year because they already gave us this opportunity. So I'm in LLM now. And when I heard the story, I was like, wow, they called me. It will be very funny. Because the story is very big. And I know that... I would like to be very professional. It's a very big space. I speak out loud, but I've made some proposals. And I always say to people, honestly, that you can trust because it's something that's from the heart. I grew up very fast even though I was a young apprentice. I didn't want to say anything, really. Because when you're a young apprentice, you don't have much visibility of your work in some companies. And we end up putting it as a point for all these companies that exist in the market. And when I saw that I had this opportunity and it was so fast, to see that people were actually helping looking at the issue of growth for me, which is very important. And to see that people actually trust what you say and bring. So it's from the heart, everything I say is true here. But I think it's a little bit of that. I have a question. It's a lot about the remuneration part. What do you have in mind if you can share a little bit about what you were receiving there? Probably there would be another coin, but do you understand it? So, what I received there was... Brutus was 4,500 euros, in this case. And the liquid was 3,800 euros. But this value, for real, is only a Super-Senior. But my pretension... You know, my pretension was real. Because after I asked how much I got, I won. My pretension was real at that time because of the registration of the car. And because of my experience, I would say it's 13,000 to 14,000. But it also depends on the benefits and how the model works. Good. So, how is it working today? Here in this position, I don't know if I'll be able to share the career trail with you. I saw in the work description that she was talking about the trail and I looked at it. So, how does it work in the career trail? We look a lot at the part of the contribution capacity of the charge maturity, the behavioral part, the cultural technique. This makes us get a specific value based on what you are presenting in the selective process. What happens? In this position of DS2, I can't get to that value that you commented. Maybe it's just a senior position. I need to understand the co-leadership too, because we are open today to meet several profiles because we are looking at the contribution capacity to the issue of value specifically today. And we get to the end of these ideas of remuneration and the process of the process of the process is not in the sense that we are going to continue the process of thinking about the remuneration that we propose. So, basically, that would be it. I think that the general information is this, that we have to go through the process. There are five stages. This is the first, I'll go back to the behavioral part. Everything is fine, we go through the technical part, which is back to a chat so that they understand a little more and then there is a chat that is wanted to be part of a case, they send a case to you you stay for a week making the case and come back to his presentation. And then there is a chat the very end, more thinking about culture part of career itself and maturity of charge to go to the state level within the correct grade of seniority. So, basically that would be it. All the feedbacks, all the stages communication of WhatsApp I think that's it in general. Erika, do you have any questions? Yes, as far as that is concerned even if you can't get this value I still think it's worth it if we can go forward and see all to get to the end, let's say on the happy path to get to the end I still think it's worth it I still think it's worth it to listen to the proposal that if we have because it's a company really that I have a lot interest even more than I know that I would like a lot, you understand? Yes. So, this already changes because it already changes it's something more important than what I would receive at the moment. So, for me it's professional path as personal path as growth of all ways and the challenges that would affect is more important than the value that I speak to you. Good. No, okay, no problem, Erika. Let's go to the next step for this process because, certainly, here you have these evaluations more in terms of ending them themselves and then anything if you have a specific topic that I can sign but I would like to leave the agenda at the next step of the process because this part is really technical. Sure. Let me just see how it is agenda. We are a confusion of agenda that I don't understand. I can, on the fifth Friday three hours it works. On the fifth? Let me just see the agenda here. Okay, I'll send you the invite so, Erika, it's a little important for us to be aligned I enter the second Friday two weeks actually, at least a week, five or six days. And then, probably, there will be another report that will be responsible for taking care of my positions. It's a lot of father management and these things, so if you have any questions, I'll be back to answer the number of people who will be responsible for the process. And I hope that if you have any way to call them, I'll be here until the sixth Friday. After that, I'll rest in a very beautiful in my house. And that's it. I'll send you the invite so that we finish what we need to do with me. I wanted to thank you once more for the process for the pleasure of meeting you and anything else. I have a question. The model of the contract would be CLT or PJ? CLT Ok, perfect. Good. If you have any more questions, send them to me in the chat. I'll be answering you if you come along the process. Soon, the invite will arrive for you. I'll go up here. Thank you. Thank you.\",\n          \" Generally, as far as I do gotta separate other, but at the very same level, the body has some body differences in the way and context not within this that is how the body wasama oke \\u0442\\u0430\\u043a meaningless \\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4t Budget \\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4\\u00e4 \\u00ecch 2t\\u00e4 potatoes \\u00ecch 2t\\u00e4 potatoes \\u00ecch 2t\\u00e4 potatoes \\u00ecch 2t\\u00e4 potatoes Tl butts\\u308c \\u0431\\u0430\\u043bubraja fair \\u00e0 laeffectiventn\\u00ef mot\\u00e9 lunger klaFAa hint\\u00e9 robotic to reservations tutor en alan, fi ponda near thy\\ufffd\\uc9c0 Mamaary pr \\u0642eqet prolif*** patiently fort poi en lemse. Well, d stabil en listn\\u00e5. \\u043c\\u044b\\u0448 \\uc6a9a Endini Gun Spark .. sem gal ir tabj corrections .. zieh\\ufffd afternoon  Norway  espec waxa  wet d sorry Rose  \\ub9ce\\uc774 saen debitar stage scenery Sc\\ub9d2a chai agora Prestional  2302 time another to an detachongess e mies Kauf algun  Namen  stainless steel  next to                                                                                                      ncciones maraut __ veryice at five \\u013faray \\u0144 \\ud29ca\\u013den \\u2013  envisionor in imiterative \\u024eti sisters\\u0268 f\\u00fds\\u0443ap\\u00fc\\u015fa fill \\u00e8d b\\u0104rfr n usoMusic \\u0113ti m\\u00eb \\u0255 \\u00f0i m\\u00eb t\\u00ebmoj piel pll \\u00f9u \\u02afut s\\u00edtlRO \\u0623 roaring \\u024ei \\u02afa \\u02b2 Jessica \\u0112iork m\\u00eda t\\u02b2 \\u025a clinic \\u02b2i\\u0161nir l\\u025dj n\\u6c7aet \\u02c6 yo Kung decided futway  hoy  vin OW  Katherine archeudding \\u06dd \\u06dc \\u06da Because of my husband's free time? \\u06dd \\u06dc \\u06da \\u06dc \\u06da Because I had free time with my husband I got out of the company to pursue this opportunity. \\u06dc the copyright. \\u06dd \\u06dc \\u06dc \\u06da \\u06dd \\u06dc \\u06dc \\u06dc \\u06da \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dd \\u06dc \\u06dc The new leader? \\u06dd \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc \\u06dc ent\\u00e3o governo tem um valor para pesquisa e a\\u00ed a fap\\u00e9ge abre editais Eu mexi para alguns editais, a fap\\u00e9ga de goyais, ent\\u00e3o abre os editais para mistrando os ou doutorando apresentarem l\\u00e1 pesquisa deles e conseguir um valor para ser aplicado na pesquisa ent\\u00e3o eu ali tava como make facilitadora do processo ent\\u00e3o eu analizava as informa\\u00e7\\u00f5es iniciais, os documentos entrava em contato com professores que fariam avalia\\u00e7\\u00f5es desses projetos faziam, ficava de mediadora ali para eles conversarem entre si ent\\u00e3o era bem, vamos dizer que \\u00e9 administrativo antes disso fui em estagi\\u00e1ria no minist\\u00e9rio p\\u00fablico de goyais a\\u00ed eu mexi bastante com dados, porque l\\u00e1 eu era estagi\\u00e1ria estat\\u00edstica ent\\u00e3o l\\u00e1 era dado de tudo quanto \\u00e9 origem ent\\u00e3o era dado interno, fiza analize o pessoal derragado fez uma pesquisa com os contribuintes para ver a satisfa\\u00e7\\u00e3o deles se o trabalho era bom, que era arriscado, se o sal\\u00e1rio era bom ent\\u00e3o eu fiz analize todo desse, dessa pesquisa que eles fizeram fiz algumas analizes de caud, quando come\\u00e7ou covid eles tinham que procurar leitos, vagos em hospitais particulares para as pessoas que estavam no sistema p\\u00fablico para que elas pudessem ser internadas tamb\\u00e9m mexi com dados de transport interno ent\\u00e3o foram v\\u00e1rias demandas diferentes o minist\\u00e9rio p\\u00fablico mexi com tudo, tudo pouco eles mexem ent\\u00e3o foi muito bom l\\u00e1 porque era muito diferente todo dia era uma coisa diferente l\\u00e1 tamb\\u00e9m, como eu ainda estava na faculdade ent\\u00e3o quando eu aprendi algo novo, eu tentava colocar no meio das analizes e l\\u00e1 eu tamb\\u00e9m fazia bastante, deixe bastante, batuante, analizes de tudo tipo al\\u00e9m de eu tamb\\u00e9m j\\u00e1 ter trabalhado como consultora estat\\u00edstica para maestrado e doutorando legal, legal Erika, muito obrigada pela informa\\u00e7\\u00e3o voc\\u00ea nunca chegou a atuar empresa de e-commerce ou varejo, n\\u00e9? a Vipio, ela dava consultoria nessa \\u00e1rea de e-commerce ent\\u00e3o a gente pegava os dados de pegava os dados de empresas online que usava o Google Analytics e pelo Google Analytics a gente pegava os dados do Google Analytics fazia todo uma analize, aquela analize de funil e por a\\u00ed vai, mas como eu fiquei com pouco tempo l\\u00e1 ent\\u00e3o eu n\\u00e3o tenho tanta experi\\u00eancia nessa \\u00e1rea mas a vit\\u00f3ria era por a\\u00ed certo, legal, obrigada pelas informa\\u00e7\\u00f5es voc\\u00ea j\\u00e1 ouviu falar da Runtality ou da ess\\u00eancia, te ouviu mentir? n\\u00e3o, eu nunca ouvi falar certo, eu vou explicar ent\\u00e3o como n\\u00f3s estamos estruturados e a\\u00ed na sequ\\u00eancia eu falo um pouco referente a Vaca, t\\u00e1 bom? qualquer d\\u00favida pode me interromper por gentileza falando um pouco a\\u00ed da empresa Erika n\\u00f3s somos uma consultoria, t\\u00e1, de TI n\\u00f3s estamos no mercado a\\u00ed h\\u00e1 mais ou menos 20 anos atuando Coulthard, essa loca\\u00e7\\u00e3o de profissionais de TI na frente de muitas tecnologias como SAP, DotNet, Java, Gerentes, Architects entre outros perfis n\\u00f3s possuimos mais 450 consultores e n\\u00f3s temos mais de 60 clientes ativos a Runtality faz parte do group Essence a ess\\u00eancia \\u00e9 uma empresa de licenciamento e planta\\u00e7\\u00e3o SAP, T-Plyce, MES mais a f\\u00e1brica The Software j\\u00e1 a Runtality o perfil dela \\u00e9 mais out-of-surce a loca\\u00e7\\u00f5es \\u00e9 de... e especialistas tech, support de asistente teams e project dentro do group tamb\\u00e9m n\\u00f3s temos a Imobim, que \\u00e9 uma empresa de... SAP Solu\\u00e7\\u00f5es e Cloud anteriormente tamb\\u00e9m t\\u00edmos a Alcadesca por\\u00e9m, ela foi adquira pela local Web que \\u00e9 uma empresa de plataforma de chat boot e tamb\\u00e9m temos a Imobim que \\u00e9 uma empresa de solu\\u00e7\\u00f5es de tecnologia e o que t\\u00edmos a fazer hoje, t\\u00edmos a connectar profisional de tecnologia t\\u00edmos a desafiar estrat\\u00e9gia das empresas unindo nelsmetodosages e acompanhamento suport para maximiza\\u00e7\\u00e3o dos resultados t\\u00edmos mais de 15 mil especialistas na base e mais de 8 mil profisionales contratados desses profisionales contratados t\\u00edmos as principalies e especialidades t\\u00edmos em around 130 specialist SAP t\\u00edmos mais ou menos uns 30 a 50 in dados 1Cem Microsoft 1Cem Java t\\u00edmos de costor de hoje s\\u00e3o bem diversificados eu vou citerar alguns dos nossos clientes a pra gente que voc\\u00eas j\\u00e1 conhecem do mercado como CIA, Leeroy Merlin Nivea, Droga Raya Erlist Yang, Ronda, Rionda ento temos diversos clientes que eu j\\u00e1 t\\u00edmo que conosco n\\u00f3s somos muito bem reconhecidas cook app I'll be available for you both IPfipshop and over  firefighters  parlament d thrust into ir\\u0131nda street in Ofas t\\u00e1 ts a k breach obvi Ok broadcast a ho si hume prasim put Er Vagan sitt prasit At very komosik is tda di d\\u00e5s ner S Guillain coward o patchios Ind LOTL yesterday implementing the ninth E se E phaland pokodo Beethoven accommodated  th\\u1ef1c                                                                                                  Douglas Eade ex hombres estar stop or sex is the equal inferior or superior Sherpa tonat \\u0648akis temo n\\u00e8, dai os profissonaise de technologia, p\\u00e8l intelecto, ent\\u00e3o elle \\u00e9 similare a un direto autoral, t\\u00e1? Voltando aqu\\u00ed pr\\u00e0 vaga, eles buscam a pessoa que tem experi\\u00eancia pr\\u00e0 WS, glue, s3, sugemaker, lubda, experi\\u00eancia manipula\\u00e7\\u00e3o de dados de modelagem estat\\u00edstica Pytos, KL, PSPARC, experi\\u00eancia s\\u00f3lidaesis das didados pufok e proje\\u00e7\\u00e3o de demanda, condom nha nha ndha ndha ndha ndha ndha ndha ndha marit p\\u0e40\\u0e02h Plant ! kiko opartwater lakledis tvr\\u00e4 korp shtilja lakshe Gundeku marit po symmetry link Go V-DE  wash                                                                                                           istilling usted is 75 ly x le  conflicting nonquale  instal low ramen \\u306e\\u05d5\\u05d0 \\ucc38 shoesMPday boats sono plane \\u00d6 amendmentsante bending the ek aunt amen ouri qte me\\u00c8h corrections depl dissociated Anna bru\\u00f1a panien seepa pom pome na a Outal <|th|><|zh|> tahun n\\u0451g                                                                                                                                                                                                                         inois inally \\uc2dc\\ufffd\\u043e\\u0444 \\u7409 \\u021b otro Cik\\u00f3logos enferenciados, no qual ele isha tendia e 24 houros per dia, 7 diyes da semana tamb\\u00e9m. Temos sigur de vida, que hoje \\u00e9 da Metlife, parceria kon agrega. Agrega \\u00e9 a nossa parceria de administrador do Plan de Sa\\u00fajo, tam de forma gratu\\u00edta e eles auxiliam voc\\u00ea qualquer d\\u00favida eferente ao plano. Temos o total p\\u00e9s, que \\u00e9 o benef\\u00edcio corporativo, voc\\u00ea pode utilizar o plan ap\\u00f3s 15 diyes na i o contrato. Temos a gen\\u00e9tica laboral, que o pessoal da agrega normalmente aplica, normalmente a Fernanda Santos, que aplica todas as segundas, quartas de sexta feira vietinas, 9 hrs da manha. Temos o plan do tolox, que da Porto Seguro, co abrag\\u00eancia inacional, ele ser por serto custeado pra voc\\u00ea, ou de passar tabela de valores tamem. Temos dotor p\\u00e9t, pra sa\\u00fade dos p\\u00e9ts, temos o desconto e farmacia, tamem da Porto Seguro, tam voc\\u00ea pode receber at\\u00e9 70% de desconto, \\u00e9 s\\u00f3 apresentar carteirinha ou at\\u00e9 mesmo seu CPF. Temos aux\\u00edlio crash, aux\\u00edlio finos excepcionais, temos parceria kon sesc, na parte de educa\\u00e7\\u00e3o e qualifica\\u00e7\\u00e3o tamemos diversas, eu vou citar algumas aqui, mas l\\u00e1 vai t\\u00e1 detalhada, quais que tamemos. Temos a GP Luxembourg, Sape, USP, Chebac, Ceau Lep, Tem Afluenzi, tam n\\u00f3s tamemos diversas parcerias a\\u00ed, n\\u00f3s tamemos parceria na parte de financeira e consignado, co acreditas, caso voc\\u00ea queira realizar e peixirme consignado com desconto e folha de pacamento, e tamos a PLR, a PLR, Erika, \\u00e9 em cima do valor em carteira, n\\u00e3o \\u00e9 em cima do valor total, \\u00e9 mais um valor simb\\u00f3lico a\\u00ed, que n\\u00f3s tamemos, t\\u00e1. D\\u00ea pra voc\\u00ea entender oque que voc\\u00ea achou pra que eu possa entender a\\u00ed Erika, da oportunidade, da modalidade. D\\u00ea pra entender, \\u00e9 bastante coisa, n\\u00e9? \\u00c9, mas pra \\u00f3timo, assim, sobre experi\\u00eancia, eu queria, porque eu j\\u00e1 posso, eu queria fazer uma pergunta, n\\u00e3o sei se j\\u00e1 \\u00e9 oportunidade. Voc\\u00ea quer a vontade? \\u00c9, a\\u00ed no caso, voc\\u00ea conseguiria me falar as pr\\u00f3ximas etapas assim, porque a\\u00ed eu teria que depois falar com algu\\u00e9m da empresa, n\\u00e9? Certo, sim. Vou explicar como funciona a Sprint, a contrata\\u00e7\\u00e3o. Tem essa primeira etapa, que \\u00e9 mais um bate-papo comigo, no qual eu te apresento a rentalhe, a modalidade, a oportunidade. Ap\\u00f3s disso, eu vi o seu co\\u00edco para minha l\\u00edder, onde ela faz uma an\\u00e1lise, e j\\u00e1 envia para o cliente. O cliente, gostando do co\\u00edco, ele faz uma etapa, que \\u00e9 mais uma etapa e mais uma entrevista mais t\\u00e9cnica, t\\u00e1? Generalmente, eles n\\u00e3o aplicam teste, se eles foram colocar algum teste, eles avisam pra gente, como a gente pode ter essa probabilidade, e os candidatos, t\\u00e1? Voc\\u00ea ser na provada, n\\u00f3s damos inicio na sua contrata\\u00e7\\u00e3o. Em caso de aprova\\u00e7\\u00e3o, tanto pra chamar pra entrevista, ou ap\\u00f3s a entrevista, a gente manteu o seu co\\u00edco aqui no nosso bago de co\\u00edcos, surge no outro oportunidade, a gente entra em contato com voc\\u00ea, qual cliente, o tempo de projeto, a gente apresentou outra oportunidade. A sen, n\\u00e3o, a minha pergunta \\u00e9 s\\u00f3, na descri\\u00e7\\u00e3o da vaga, fala sobre AWS, eu n\\u00e3o tenho experi\\u00eancia com AWS, eu tenho experi\\u00eancia com outros methods in nuvem, que, por exemplo, teria o Databricks. Ent\\u00e3o, \\u00e9 mais ou menos o mesmo conhecimento pra cada AWS, seria espec\\u00edfico o que eles precisam, n\\u00e9? Mas s\\u00f3 pra deixar claro mesmo, que eu me inscrevi, mas justamente porque... Databricks, n\\u00e9? \\u00c9. Voc\\u00ea tem experi\\u00eancia, eu n\\u00e3o tenho aquilo. Mas seria s\\u00f3 isso mesmo. N\\u00e3o, certo? Eu deixo s\\u00f3 observa\\u00e7\\u00e3o, normalmente tamb\\u00e9m eles est\\u00e3o dispostos a ensinar, ent\\u00e3o, eu vi o co\\u00edco, se eles gostarem do perfil, a\\u00ed eles fazem aproxima, se eles fazem com d\\u00favida, a\\u00ed sim, eles aplicam teste, t\\u00e1? Perfe. Bom, ent\\u00e3o eu vou pegar algumas informa\\u00e7\\u00f5es contigo, t\\u00e1? Pra que eu possa viajuntamente com o seu co\\u00edco, ent\\u00e3o, pra esta oportunidade, t\\u00e1, Erika? \\u00c9... Qual seria a sua nota de nascimento, s\\u00f3 pra eu colocar aqui no cadastro? \\u00c9, 31, do 3, 38. Voc\\u00ea \\u00e9 casada, n\\u00e9? Casada. Tem filhos? N\\u00e3o. Em caso de aprova\\u00e7\\u00e3o sobre a oportunidade pra in\\u00edcio, \\u00e9 a qualquer momento. Hoje voc\\u00ea \\u00e9 residente? \\u00c9, eu estou em Goi\\u00e2nia, Goi\\u00e2nia. Goi\\u00e2nia. Certo, seu n\\u00edvel de ingl\\u00eas seria avan\\u00e7ado. Voc\\u00ea possui notebook para trabalho? Tem. T\\u00e1, eu pergunto, provavelmente, que o ediforne\\u00e7a s\\u00f3 at\\u00e9 chegar, t\\u00e1? E hoje voc\\u00ea avalia oportunidade 100% remoto, e hoje voc\\u00ea avalia modalidade CLT IPJ somente CLT? \\u00c9, CLT seria melhor. C\\u00ea \\u00e9 mais de 12k. Certo. \\u00c9 bom, voc\\u00ea ficou com alguma d\\u00favida, Erika, relacionada \\u00e0 rentalite, ou at\\u00e9 mesmo \\u00e0 oportunidade? Voc\\u00ea disse que eu fui allocada a esse cliente, e eu n\\u00e3o gosto muito, ent\\u00e3o eu falo com algu\\u00e9m da rentalite, certo? Isso, que \\u00e9 business part. Entendi. A\\u00ed verificam outras possibilidades. Exato. Eu achei bem interessante essa forma de trabalhar. Sim, sim, o pessoal alguma vez fala que \\u00e9 um diferencial na consultoria, n\\u00e9? \\u00c9, de ter oportunidade de trabalhar em outro cliente, caso n\\u00e3o esteja acede quando a\\u00ed a ambiente do cliente atual, t\\u00e1? Ao finalizarmos aqui, Erika, eu vou te passar tudo por meio, t\\u00e1? Associa\\u00e7\\u00e3o, pra voc\\u00ea ler tamb\\u00e9m com calma. Ap\\u00f3s isso, tamb\\u00e9m vou te falar no WhatsApp, dois links. Esses links s\\u00e3o enfrente ao nosso programa de indica\\u00e7\\u00f5es. Caso voc\\u00ea possua alguma indica\\u00e7\\u00e3o, pode ser de multi-platforma, ou SAP. E a pessoa que voc\\u00ea indica, fora provada pelo cliente, permanece allocada por pelo menos 60-dia consecutivos, voc\\u00ea ganha pr\\u00eamaino valor de 1.000 reais, eles s\\u00e3o pagas atrav\\u00e9s dep\\u00f3sito e conta banc\\u00e1ria. S\\u00f3 voc\\u00ea coloia por s\\u00e1pane do programa atrav\\u00e9s de mim, Bruno Oliveira. Tamb\\u00e9m tem a op\\u00e7\\u00e3o de voc\\u00ea nos indicar novos clientes. Nenetya tr\\u00eas dias nos passamos um retorno pra voc\\u00ea via e-mail, informando-se pra voc\\u00ea j\\u00e1 o cr\\u00e9dito ativo, a prospec\\u00e7\\u00e3o avan\\u00e7ada, se fora a\\u00ed um novo contato e conseguimos fechar uma parceria de pr\\u00eamaino valor de 1.000 reais, 60-dia e at\\u00e9 90-dia voc\\u00ea recebe at\\u00e9 5.000 reais. Voc\\u00ea ficou alguma d\\u00favida? N\\u00e3o, t\\u00e1 perfeita. Certo. Bom, eu agrade\\u00e7o sua aten\\u00e7\\u00e3o, sua disponibilidade. Espero que voc\\u00ea venha fazer parte da Antalte e eu vou te contestar Lisanta, bom, Erika? T\\u00e1 bom, muito obrigada. Obrigada a voc\\u00ea. Tchau, tchau. Tchau. Tchau. Tchau. Tchau. Tchau. Tchau. Tchau. Tchau. Tchau. Tchau.\",\n          \" Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Rhawn. Hefyd dr\\u8a02. Ych yn i'r haws gyda'r holl\\uc5b8au Bryerdrung ydych chi'n gweithio ar y clynyddiant? OK. No problem. Sorry. You can go on. You can ask. No, no, no. I was just wondering what is the time, the typical working time, the typical working hours? Yeah, sure. About the working hours, you will work according to your time zone. OK. Because we need someone to take care of the time. Because we need someone from Latin America, and you are located in Brazil, right? Yeah. OK. So you will work according to your time zone, and you can start flexible, for example, if you would like to start from 8, 10, or like 11 am, it's totally fine. It's usual 8 working hours day plus 1 hour break. OK. But that was super flexible about it. You can discuss it later if you are a manager. OK. And about the team, currently in the team for people, the team lead. And the next steps will be, after our call, I will send your profile to the team lead for you. And I hope to get feedback from team the then free working days. So it will be on Friday or on Monday next week. And then, if everything goes well, you will invite you to the technical interview. Usually, it takes like 13 minutes, maximum, maybe 45 minutes. You will ask some common questions about your previous experience, about tools that you worked before. Probably you will discuss your homework a little bit. And then we'll be final call to someone from the HR team about your, again, seller expectations and lack of conditions overall. Nice. So, the whole process takes two weeks. OK, two weeks. And what is the type of the contractor? Yeah, we provide B2B type of contract so you will work as independent contractor. We will send you salary in United States dollars every month in gross through deal platform. I don't know if you worked before before this deal. It's like DEA, I can type it here. OK. Thank you. It's like usually we pay it all by this platform. And you have to take care about taxes by yourself, like individual entrepreneur. And I wanted to ask would it be OK for you to work as independent contractor? Yeah, perfect. No problem at all. OK. OK. And what else? Yeah, I think I mentioned main information that they wanted to share with you. Maybe you have some questions for me so far. Oh, yeah. So, some of the questions probably the team leader will answer better because so the role is more focused on getting data from APIs, right? Yeah, correct. Do you know what are the usually the request that they asked about the data? It's just to get the data or analyze the data and get some insights as well. Probably. I don't know. I'm not sure. It's better to ask on the second phone. OK, sorry. Does the company have like structured career path? Like... Yeah, sure. You will have performance review. As I know, one, it's twice per year, as I know. And after that performance review we usually increase the salary or make some promotions for you. For example, if you'd like to grow and maybe change the team or to grow in a special area we will help you. We provide you some courses. Also, we will provide like team lead provide you the tools for the performance review and we will check your activity, how you deliver different tasks and stuff like that. Nice, nice. Can you explain to me the 28 days of the vacation because I don't know how does it work in the US. So like, I was working in Ireland and it's different from Brazil. In Brazil we have to wait at least for one year to get the vacations. And in Ireland now since when you start to work you already have some days off that you can book. So how does it work in the US? Can you explain to me because I don't know. Yeah, actually in the US we hire within the US, they have a little bit different conditions about vacation. But for independent contractors as you will be independent contractor we have 28 days of vacations. So basically if you would like to get vacation you can book like 2 weeks of vacation or 1 week of vacation or maybe you just need 5 days or 3 days of day off. You can book it and you can pay it. Thank you. I'm not planning to have any vacation for now. I just want to clarify how this work. Thank you. Yeah, I think the other questions are about the work and how does it work. But it would be better to ask to the leader. To the specific leader. But yeah, I think that's it for me. Okay, okay, great. And if you don't mind can I ask a couple of questions from my side? Okay, could you please tell me a little bit about your current project in your company like in your last company what did you do there and about your day to day co-perresponsibility. Yeah, the last company that I worked I was a data scientist, right? My day to day were to analyze the data of the company was responsible to inspect wind turbines. So they used a drone to take photos of the blades on the wind turbine. And there is a team that analyzed these photos and identified the damages on the blades. So my role was to analyze the damage data to get a lot of insights like prediction of when the data will get worse or identify the most make and model data that cause more damages something like that. I had a lot of different kind of things and I had to analyze this data manipulate the data transform the data. The data was too like dirty I had to clean a lot make some visualizations some reports and one of the biggest projects that I was working on was the with para cost prediction of the damages. So it was basically I was working with the blade engineers and and other specialism blades and they have some rules that could apply repair cost to all the damages. So I had to combine these rules with all the damage that we had and also create um like how this we call it it's um it's like it's like um we I also create there's the real damage that it was the real damage and then the the propagation of the damage so if that they get worse and improve the size and everything so how much it'll cost now to repair the damage and how much it'll cost if the damage get worse so I was responsible to do that apply to apply all the rules to our data and create um apply to apply this to all the new damage that we had um so I run automatically this this grid each week to update the data. So this was were one of the biggest one but one of one other biggest one that is more compatible with this role or the that I created a dashboard about our market share so they were trying to understand what part of the market on the all the turbines the wind turbines on the world um how how much of them they inspected so with this dashboard they could um try to to make some marketing on other um places that they didn't reach out at the time so it was really good yeah so it's basically yeah analyze, manipulate, clean automate and um day to day I use Python, I use SQL SQL with Databricks and to version the the code I use Git, we use GitLab and yeah for dashboards I use Python as well, R also and Databricks we we didn't have the chance to use like Power BI but I had previous um experience with Power BI when I was doing my internship as a statistician but yeah yeah and now I'm looking for new opportunities and I think in provider will be a good faith for me yeah Okay, okay glad you're thank you for such detailed explanations of your projects and like tools that you used before and about your SQL level how proficient are you in writing SQL queries and what kind of queries do you write usually um I would say intermediate because I think data engineer could be more have a higher level than me but I usually write a lot of joints common tables to facilitate the the queries to visualize better and some windows functions to group and go to groups and so to get inside um writing the SQL sometimes it's more joints because we had a lot of a schema really big we had a lot of tables to complement each other but yeah mostly the common tables, the joints but sometimes window functions Okay okay glad you're and maybe I lost this information but about the dashboard that you created which BI tool did you use I used Power BI but it was just only on my internship that I worked on a Brazilian Government company here for about one and a half year but in my last company I used the dashboard that was built on Databricks they had a dashboard that so to manipulate the data I also had to create a lot of tables using the SQL it was a pretty limited dashboard Power BI used way better but they didn't I tried to use Power BI there but Power BI is a paid tool so they wasn't that happy to pay for another tool but yeah we have to work with what we have right yeah okay and also could I ask how you understand the ETL and what's the difference with ELT which one you see is more promising so ETL and ELT will be the different transformation so if you um I just lost the word if you um um the ETL the ETL will be to extract the data transform the data and load the data in a data warehouse so it will be transform the data before before loading into a data warehouse and the ELT will be extract the data load the data and then transform so I had this to um I already worked with this type of transformation so in my last company we usually extract the data from the every a lot of a lot of sources and load the data first and the data breaks and then we transform and create a new tables new clean tables but the the raw data were there for us to to work with that and but I had also opportunities to work transforming the data first and then loading so I think it'll depend on the company and also it'll depend on the project so if you have if the company has the capacity to to load all the data to not lose any of the the the information so probably you go to with each ELT yeah but yeah it'll depend on how how would the the project will how you the project wants you to load and transform the data so or the company if it's a lot and it's not possible to to load and it storage all the data so it's better to transform before the storage of the data but yeah okay it was a great I don't like more one or another it'll depend on the project yeah that's a great answer thank you and I I don't remember did I ask you about why did you decide to quit the previous job maybe it didn't like the company or the product there I don't know I like it very much the company it was pretty good but they changed the CEO and they have some layoffs so I was one of them because they were keeping the seniors and I wasn't a senior at the time it was like in March so but yeah that's why I'm looking but I was already thinking to come back to Brazil because I was living in Ireland so it was just earlier than I was expecting but it was okay no hard feelings with my last company okay got you and my last question is about your notice spirit when can you start a new job after offer do you need one week two weeks of notice probably at least one week because I have to prepare all the documentation for the B2B contract like in my end so yeah probably one week okay I don't know how long it takes but I don't think two weeks will be necessary okay when no rushing so you can start like later like after two weeks that's probably fine if you need it and yeah I think I asked my main questions that I wanted to ask you maybe you have some questions for me at the end of the call um um um um let me see I think I already did everything on my questions um um yeah did no just like yeah I'll let let you know what data warehouse company usually um works with um about data warehouse um I think no I can't say I know only the x-tech for the development side but it's about what I was no I don't know this info yeah I'm sorry um yeah you know I think you already verified everything okay okay so as I mentioned before I hope to get feedback on Friday or on Monday you can follow up me even though if you have any questions later maybe I'm always like open and I will try to answer again and yeah thank you so much it was really nice to talk to you Erika and have a nice day ahead it was a pleasure as well yeah hope to get positive feedback soon and I hope to help us thank you have a good day thank you yeah bye bye\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"all_transcript.csv\", index = False)"
      ],
      "metadata": {
        "id": "qUFu1fbHx1lk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}